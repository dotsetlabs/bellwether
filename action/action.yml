name: 'Bellwether MCP Interview'
description: 'Behavioral testing, documentation generation, and drift detection for MCP servers'
author: 'Dotset Labs LLC'

branding:
  icon: 'shield'
  color: 'purple'

inputs:
  server-command:
    description: 'MCP server command to test (e.g., "npx @modelcontextprotocol/server-filesystem")'
    required: true
  server-args:
    description: 'Arguments to pass to the server command'
    required: false
    default: ''
  preset:
    description: 'Interview preset: docs, security, thorough, ci (overrides personas/max-questions)'
    required: false
  personas:
    description: 'Comma-separated list of personas (technical_writer, security_tester, qa_engineer, novice_user). Ignored if preset is set.'
    default: 'technical_writer'
  max-questions:
    description: 'Maximum questions per tool. Ignored if preset or quick is set.'
    default: '3'
  quick:
    description: 'Quick mode for fast CI runs (1 question per tool, cheaper model). Recommended for PR checks.'
    default: 'false'
  baseline-path:
    description: 'Path to behavioral baseline file for drift detection'
    required: false
  fail-on-drift:
    description: 'Fail the action if behavioral drift is detected'
    default: 'true'
  strict:
    description: 'Strict mode: only report structural (deterministic) changes for CI'
    default: 'false'
  min-confidence:
    description: 'Minimum confidence score (0-100) to report a change'
    default: '0'
  confidence-threshold:
    description: 'Confidence threshold (0-100) for CI to fail on breaking changes'
    default: '80'
  security:
    description: 'Include security testing persona'
    default: 'false'
  save-baseline:
    description: 'Save baseline after interview. Set to "true" or provide a path.'
    required: false
    default: 'false'
  output-json:
    description: 'Also generate JSON report (bellwether-report.json)'
    default: 'false'
  output-dir:
    description: 'Directory for output files'
    default: '.'
  scenarios-path:
    description: 'Path to custom test scenarios YAML file'
    required: false
  scenarios-only:
    description: 'Run only custom scenarios (no LLM required)'
    default: 'false'
  timeout:
    description: 'Timeout for tool calls in milliseconds'
    default: '30000'
  llm-provider:
    description: 'LLM provider (auto-detected from API key env vars). Only set to override detection.'
    required: false
  llm-model:
    description: 'LLM model to use. Defaults to gpt-5-mini (openai) or claude-haiku-4-5 (anthropic) in quick mode.'
    required: false
  openai-api-key:
    description: 'OpenAI API key (alternative to OPENAI_API_KEY env var)'
    required: false
  anthropic-api-key:
    description: 'Anthropic API key (alternative to ANTHROPIC_API_KEY env var)'
    required: false

outputs:
  result:
    description: 'Check result: passed or failed'
    value: ${{ steps.interview.outputs.result }}
  exit-code:
    description: 'Exit code (0=pass, 1=drift/security fail, 2=error)'
    value: ${{ steps.interview.outputs.exit-code }}
  drift-detected:
    description: 'Whether behavioral drift was detected (true/false)'
    value: ${{ steps.interview.outputs.drift-detected }}
  security-tested:
    description: 'Whether security persona was included'
    value: ${{ steps.interview.outputs.security-tested }}
  tool-count:
    description: 'Number of tools discovered'
    value: ${{ steps.interview.outputs.tool-count }}
  error-count:
    description: 'Number of errors encountered'
    value: ${{ steps.interview.outputs.error-count }}
  agents-md:
    description: 'Path to generated AGENTS.md file'
    value: ${{ steps.interview.outputs.agents-md }}
  json-report:
    description: 'Path to JSON report file (if output-json is true)'
    value: ${{ steps.interview.outputs.json-report }}
  baseline-file:
    description: 'Path to saved baseline file'
    value: ${{ steps.interview.outputs.baseline-file }}

runs:
  using: 'composite'
  steps:
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'

    - name: Install Bellwether
      shell: bash
      run: npm install -g @dotsetlabs/bellwether

    - name: Run Bellwether Interview
      shell: bash
      id: interview
      env:
        BELLWETHER_CI: 'true'
        OPENAI_API_KEY: ${{ inputs.openai-api-key || env.OPENAI_API_KEY }}
        ANTHROPIC_API_KEY: ${{ inputs.anthropic-api-key || env.ANTHROPIC_API_KEY }}
      run: |
        set +e

        # Build the command
        CMD="bellwether interview"
        CMD="$CMD --timeout ${{ inputs.timeout }}"

        OUTPUT_DIR="${{ inputs.output-dir }}"
        CMD="$CMD -o $OUTPUT_DIR"

        # Preset takes precedence over individual settings
        if [ -n "${{ inputs.preset }}" ]; then
          CMD="$CMD --preset ${{ inputs.preset }}"
          echo "::notice::Using preset: ${{ inputs.preset }}"
        elif [ "${{ inputs.quick }}" = "true" ]; then
          CMD="$CMD --quick"
          echo "::notice::Running in quick mode (1 question per tool, cheaper model)"
        else
          CMD="$CMD --personas ${{ inputs.personas }}"
          CMD="$CMD --max-questions ${{ inputs.max-questions }}"
        fi

        # Add model if specified
        if [ -n "${{ inputs.llm-model }}" ]; then
          CMD="$CMD --model ${{ inputs.llm-model }}"
        fi

        # Add security persona if requested
        if [ "${{ inputs.security }}" = "true" ]; then
          CMD="$CMD --security"
          echo "security-tested=true" >> $GITHUB_OUTPUT
        else
          echo "security-tested=false" >> $GITHUB_OUTPUT
        fi

        # Add baseline comparison if specified
        if [ -n "${{ inputs.baseline-path }}" ]; then
          CMD="$CMD --compare-baseline ${{ inputs.baseline-path }}"
        fi

        # Add baseline saving if specified
        if [ "${{ inputs.save-baseline }}" = "true" ]; then
          CMD="$CMD --save-baseline"
        elif [ -n "${{ inputs.save-baseline }}" ] && [ "${{ inputs.save-baseline }}" != "false" ]; then
          CMD="$CMD --save-baseline ${{ inputs.save-baseline }}"
        fi

        # Add fail-on-drift flag
        if [ "${{ inputs.fail-on-drift }}" = "true" ]; then
          CMD="$CMD --fail-on-drift"
        fi

        # Strict mode for deterministic results
        if [ "${{ inputs.strict }}" = "true" ]; then
          CMD="$CMD --strict"
        fi

        # Confidence threshold options
        if [ "${{ inputs.min-confidence }}" != "0" ]; then
          CMD="$CMD --min-confidence ${{ inputs.min-confidence }}"
        fi

        if [ "${{ inputs.confidence-threshold }}" != "80" ]; then
          CMD="$CMD --confidence-threshold ${{ inputs.confidence-threshold }}"
        fi

        # Custom scenarios support
        if [ -n "${{ inputs.scenarios-path }}" ]; then
          CMD="$CMD --scenarios ${{ inputs.scenarios-path }}"
        fi

        if [ "${{ inputs.scenarios-only }}" = "true" ]; then
          CMD="$CMD --scenarios-only"
        fi

        # Output JSON report if requested
        if [ "${{ inputs.output-json }}" = "true" ]; then
          CMD="$CMD --json"
          echo "json-report=${OUTPUT_DIR}/bellwether-report.json" >> $GITHUB_OUTPUT
        fi

        # Add the server command and args
        CMD="$CMD ${{ inputs.server-command }} ${{ inputs.server-args }}"

        echo "Running: $CMD"
        OUTPUT=$(eval $CMD 2>&1)
        EXIT_CODE=$?

        echo "$OUTPUT"

        # Set outputs
        echo "exit-code=$EXIT_CODE" >> $GITHUB_OUTPUT

        # Check for AGENTS.md
        AGENTS_MD="${OUTPUT_DIR}/AGENTS.md"
        if [ -f "$AGENTS_MD" ]; then
          echo "agents-md=$AGENTS_MD" >> $GITHUB_OUTPUT
        fi

        # Check for baseline file
        BASELINE="${OUTPUT_DIR}/bellwether-baseline.json"
        if [ -f "$BASELINE" ]; then
          echo "baseline-file=$BASELINE" >> $GITHUB_OUTPUT
        fi

        # Extract tool count from output
        TOOL_COUNT=$(echo "$OUTPUT" | grep -oP 'Discovered \K\d+(?= tools)' || echo "0")
        echo "tool-count=$TOOL_COUNT" >> $GITHUB_OUTPUT

        # Extract error count from output
        ERROR_COUNT=$(echo "$OUTPUT" | grep -oP '\K\d+(?= errors)' || echo "0")
        echo "error-count=$ERROR_COUNT" >> $GITHUB_OUTPUT

        # Check for drift detection
        if echo "$OUTPUT" | grep -qi "drift detected"; then
          echo "drift-detected=true" >> $GITHUB_OUTPUT
        else
          echo "drift-detected=false" >> $GITHUB_OUTPUT
        fi

        # Check JSON report
        JSON_REPORT="${OUTPUT_DIR}/bellwether-report.json"
        if [ -f "$JSON_REPORT" ]; then
          echo "json-report=$JSON_REPORT" >> $GITHUB_OUTPUT
        fi

        # Set result and provide helpful messages
        if [ $EXIT_CODE -eq 0 ]; then
          echo "result=passed" >> $GITHUB_OUTPUT
          echo "::notice::Bellwether interview passed"
        elif [ $EXIT_CODE -eq 1 ]; then
          echo "result=failed" >> $GITHUB_OUTPUT
          echo "::error::Bellwether check failed. Review the output above for details."
          echo ""
          echo "If drift was detected and changes are intentional, update your baseline:"
          echo "  bellwether interview --save-baseline ${{ inputs.baseline-path || './bellwether-baseline.json' }} ${{ inputs.server-command }}"
        elif [ $EXIT_CODE -eq 2 ]; then
          echo "result=failed" >> $GITHUB_OUTPUT
          echo "::error::Bellwether interview failed with errors."
          echo ""
          echo "Common issues:"
          echo "  - MCP server failed to start: check your server-command"
          echo "  - LLM API key not set: add OPENAI_API_KEY or ANTHROPIC_API_KEY secret"
          echo "  - Server timeout: increase timeout input"
        else
          echo "result=failed" >> $GITHUB_OUTPUT
          echo "::error::Bellwether interview failed with exit code $EXIT_CODE"
        fi

        exit $EXIT_CODE

    - name: Upload AGENTS.md artifact
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: bellwether-docs
        path: ${{ inputs.output-dir }}/AGENTS.md
        if-no-files-found: ignore

    - name: Upload baseline artifact
      if: inputs.save-baseline != 'false' && always()
      uses: actions/upload-artifact@v4
      with:
        name: bellwether-baseline
        path: ${{ inputs.output-dir }}/bellwether-baseline.json
        if-no-files-found: ignore

    - name: Upload JSON report artifact
      if: inputs.output-json == 'true' && always()
      uses: actions/upload-artifact@v4
      with:
        name: bellwether-report
        path: ${{ inputs.output-dir }}/bellwether-report.json
        if-no-files-found: ignore
