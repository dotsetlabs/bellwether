# Bellwether CLI Configuration
# Copy this file to .env and fill in your values
#
# For users: Only the LLM provider section is required (and only for document mode)
# For developers: See the Development section at the bottom

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Required for document mode testing. Contract mode (default) requires no API keys.
# Choose at least one provider if using document mode.

# OpenAI - recommended for best interview results
# Get your key at: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-key-here

# Anthropic Claude - excellent alternative with strong reasoning
# Get your key at: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# Ollama - free, runs locally (no API key needed)
# Install from: https://ollama.ai
# Default URL is http://localhost:11434, only set if using non-standard port
# OLLAMA_BASE_URL=http://localhost:11434

# =============================================================================
# BELLWETHER CLOUD CONFIGURATION
# =============================================================================
# Required for cloud features (baseline history, badges, team collaboration)

# Session token for cloud authentication
# Get from `bellwether login` after authenticating via GitHub OAuth
# Required for CI/CD pipelines where interactive login isn't possible
# BELLWETHER_SESSION=sess_your-session-token-here

# Cloud API URL
# Default: https://api.bellwether.sh
# Only change for self-hosted instances or local development
# BELLWETHER_API_URL=http://localhost:3000

# Team ID override for multi-team users
# When you belong to multiple teams, use this to specify which team context
# to use for cloud operations. Useful in CI/CD when your account has multiple teams.
# Get team IDs from `bellwether teams` command
# BELLWETHER_TEAM_ID=team_your-team-id-here

# =============================================================================
# CI/CD ENVIRONMENT (auto-detected, no configuration needed)
# =============================================================================
# Bellwether automatically detects these CI environments and extracts metadata:
#
# GitHub Actions:
#   GITHUB_ACTIONS, GITHUB_RUN_ID, GITHUB_REF_NAME, GITHUB_SHA
#
# GitLab CI:
#   GITLAB_CI, CI_JOB_ID, CI_COMMIT_REF_NAME, CI_COMMIT_SHA
#
# CircleCI:
#   CIRCLECI, CIRCLE_BUILD_NUM, CIRCLE_BRANCH, CIRCLE_SHA1
#
# Jenkins:
#   JENKINS_URL, BUILD_NUMBER, GIT_BRANCH, GIT_COMMIT
#
# Travis CI:
#   TRAVIS, TRAVIS_BUILD_NUMBER, TRAVIS_BRANCH, TRAVIS_COMMIT
#
# Buildkite:
#   BUILDKITE
#
# Generic CI detection:
#   CI, CONTINUOUS_INTEGRATION

# =============================================================================
# DEVELOPMENT (for contributors and forkers)
# =============================================================================
# These settings are for developers working on the Bellwether CLI itself.

# --- LLM Testing ---
# For testing LLM integrations, you'll need at least one provider key.
# We recommend starting with Ollama for free local testing:
#   1. Install Ollama: https://ollama.ai
#   2. Run: ollama serve
#   3. Pull a model: ollama pull llama3.2
# No API key needed for Ollama.

# --- Cloud Development ---
# If working on cloud integration features:
#   1. Start the local cloud server (from /platform/cloud):
#      npm run dev
#   2. Set the API URL to your local instance:
#      BELLWETHER_API_URL=http://localhost:3000
#   3. Use mock mode for testing without real GitHub OAuth:
#      bellwether login --mock

# --- Running Tests ---
# Unit tests don't require any environment variables.
# Integration tests may need LLM provider keys.
#   npm test           # Run all tests
#   npm run test:watch # Watch mode

# --- Debug Output ---
# The CLI uses pino for logging. Set log level in bellwether.yaml:
#   logging:
#     level: debug  # debug, info, warn, error, silent

# =============================================================================
# SENSITIVE VARIABLES (automatically filtered)
# =============================================================================
# The following environment variables are automatically filtered when spawning
# MCP server subprocesses for security:
#
# LLM API Keys:
#   OPENAI_API_KEY, ANTHROPIC_API_KEY, AZURE_OPENAI_API_KEY,
#   COHERE_API_KEY, HUGGINGFACE_API_KEY, REPLICATE_API_TOKEN
#
# Cloud Provider Credentials:
#   AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN, AZURE_CLIENT_SECRET,
#   GOOGLE_APPLICATION_CREDENTIALS
#
# SCM/CI Tokens:
#   GITHUB_TOKEN, GH_TOKEN, GITLAB_TOKEN, BITBUCKET_TOKEN,
#   NPM_TOKEN, PYPI_TOKEN
#
# Database Credentials:
#   DATABASE_URL
#
# Bellwether:
#   BELLWETHER_SESSION
