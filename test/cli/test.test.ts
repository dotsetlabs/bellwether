import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
import { mkdirSync, rmSync, existsSync, readFileSync, writeFileSync } from 'fs';
import { join } from 'path';
import { tmpdir } from 'os';
import { resetLogger, configureLogger } from '../../src/logging/logger.js';

// Mock modules before importing the command - vitest 4.x requires class syntax for constructor mocks
vi.mock('../../src/transport/mcp-client.js', () => {
  return {
    MCPClient: class MockMCPClient {
      connect = vi.fn().mockResolvedValue(undefined);
      disconnect = vi.fn().mockResolvedValue(undefined);
      callTool = vi.fn().mockResolvedValue({
        content: [{ type: 'text', text: 'result' }],
        isError: false,
      });
    },
  };
});

vi.mock('../../src/llm/index.js', () => {
  return {
    createLLMClient: vi.fn().mockReturnValue({
      chat: vi.fn().mockResolvedValue({
        content: [{ type: 'text', text: '{"questions": []}' }],
      }),
    }),
  };
});

// Test the interview command helper function and related functionality
describe('cli/interview', () => {
  let testDir: string;
  let originalCwd: string;
  let consoleOutput: string[];
  let consoleErrors: string[];
  let stdoutOutput: string[];

  beforeEach(() => {
    // Silence logger during tests
    configureLogger({ level: 'silent' });

    // Create temp directory
    testDir = join(tmpdir(), `bellwether-cli-interview-test-${Date.now()}`);
    mkdirSync(testDir, { recursive: true });
    originalCwd = process.cwd();
    process.chdir(testDir);

    // Capture console output
    consoleOutput = [];
    consoleErrors = [];
    stdoutOutput = [];
    vi.spyOn(console, 'log').mockImplementation((...args) => {
      consoleOutput.push(args.join(' '));
    });
    vi.spyOn(console, 'error').mockImplementation((...args) => {
      consoleErrors.push(args.join(' '));
    });
    vi.spyOn(process.stdout, 'write').mockImplementation((data: string | Uint8Array) => {
      stdoutOutput.push(typeof data === 'string' ? data : data.toString());
      return true;
    });
  });

  afterEach(() => {
    process.chdir(originalCwd);
    resetLogger();
    vi.restoreAllMocks();
    try {
      rmSync(testDir, { recursive: true, force: true });
    } catch {
      // Ignore cleanup errors
    }
  });

  describe('extractServerContextFromArgs', () => {
    // Import the function dynamically to test it
    it('should detect filesystem server with allowed directories', async () => {
      // Test the logic for filesystem server detection
      const command = 'npx';
      const args = ['@modelcontextprotocol/server-filesystem', '/home/user/docs', '/tmp/allowed'];
      const fullCommand = `${command} ${args.join(' ')}`.toLowerCase();

      // Check detection logic
      const isFilesystem =
        fullCommand.includes('filesystem') || fullCommand.includes('file-system');
      expect(isFilesystem).toBe(true);

      // Extract paths
      const paths = args.filter((arg) => arg.startsWith('/') && !arg.startsWith('--'));
      expect(paths).toEqual(['/home/user/docs', '/tmp/allowed']);
    });

    it('should detect database servers', () => {
      const testCases = [
        { command: 'npx', args: ['@mcp/postgres', '--db', 'mydb'] },
        { command: 'npx', args: ['@mcp/mysql-server', '--host', 'localhost'] },
        { command: 'npx', args: ['@mcp/sqlite', '/data/db.sqlite'] },
      ];

      for (const { command, args } of testCases) {
        const fullCommand = `${command} ${args.join(' ')}`.toLowerCase();
        const isDatabase =
          fullCommand.includes('postgres') ||
          fullCommand.includes('mysql') ||
          fullCommand.includes('sqlite');
        expect(isDatabase).toBe(true);
      }
    });

    it('should extract absolute paths from arguments', () => {
      const args = [
        'server-name',
        '/absolute/path',
        '--option',
        'value',
        '/another/path',
        '--flag',
      ];

      const paths = args.filter((arg) => arg.startsWith('/') && !arg.startsWith('--'));
      expect(paths).toEqual(['/absolute/path', '/another/path']);
    });

    it('should ignore relative paths', () => {
      const args = ['./relative/path', '../parent/path', 'no/slash', '/absolute/valid'];

      const paths = args.filter((arg) => arg.startsWith('/') && !arg.startsWith('--'));
      expect(paths).toEqual(['/absolute/valid']);
    });
  });

  describe('interview output generation', () => {
    it('should create AGENTS.md in output directory', () => {
      // Simulate what the interview command does
      const outputDir = testDir;
      const agentsPath = join(outputDir, 'AGENTS.md');

      const content = `# Test Server

> Generated by Bellwether

## Overview

This is a test server.
`;
      writeFileSync(agentsPath, content);

      expect(existsSync(agentsPath)).toBe(true);
      const written = readFileSync(agentsPath, 'utf-8');
      expect(written).toContain('# Test Server');
    });

    it('should create JSON report when --json option used', () => {
      const outputDir = testDir;
      const jsonPath = join(outputDir, 'bellwether-report.json');

      const report = {
        discovery: {
          serverInfo: { name: 'test', version: '1.0.0' },
          tools: [],
        },
        toolProfiles: [],
        metadata: {
          startTime: new Date().toISOString(),
          endTime: new Date().toISOString(),
          durationMs: 1000,
          toolCallCount: 5,
          errorCount: 0,
        },
      };
      writeFileSync(jsonPath, JSON.stringify(report, null, 2));

      expect(existsSync(jsonPath)).toBe(true);
      const parsed = JSON.parse(readFileSync(jsonPath, 'utf-8'));
      expect(parsed.discovery.serverInfo.name).toBe('test');
    });
  });

  describe('baseline functionality', () => {
    it('should save baseline to default path', () => {
      const outputDir = testDir;
      const baselinePath = join(outputDir, 'bellwether-baseline.json');

      const baseline = {
        version: '1.0.0',
        metadata: {
          mode: 'check',
          generatedAt: new Date().toISOString(),
          cliVersion: '1.0.0',
          serverCommand: 'npx @test/server',
          durationMs: 1,
          personas: [],
          model: 'none',
        },
        server: {
          name: 'test',
          version: '1.0.0',
          protocolVersion: '2024-11-05',
          capabilities: ['tools'],
        },
        capabilities: {
          tools: [
            {
              name: 'test_tool',
              description: 'Test tool',
              inputSchema: { type: 'object', properties: {} },
              schemaHash: 'abc123',
            },
          ],
        },
        interviews: [],
        toolProfiles: [],
        assertions: [],
        summary: 'Test baseline',
        hash: 'abc123',
      };
      writeFileSync(baselinePath, JSON.stringify(baseline, null, 2));

      expect(existsSync(baselinePath)).toBe(true);
      const loaded = JSON.parse(readFileSync(baselinePath, 'utf-8'));
      expect(loaded.version).toBe('1.0.0');
      expect(loaded.capabilities.tools[0].name).toBe('test_tool');
    });

    it('should save baseline to custom path', () => {
      const customPath = join(testDir, 'custom', 'baseline.json');
      mkdirSync(join(testDir, 'custom'), { recursive: true });

      const baseline = {
        version: '1.0.0',
        metadata: {
          mode: 'check',
          generatedAt: new Date().toISOString(),
          cliVersion: '1.0.0',
          serverCommand: 'npx test-server',
          durationMs: 1,
          personas: [],
          model: 'none',
        },
        server: {
          name: 'test',
          version: '1.0.0',
          protocolVersion: '2024-11-05',
          capabilities: [],
        },
        capabilities: { tools: [] },
        interviews: [],
        toolProfiles: [],
        assertions: [],
        summary: 'Test baseline',
        hash: 'hash',
      };
      writeFileSync(customPath, JSON.stringify(baseline));

      expect(existsSync(customPath)).toBe(true);
    });

    it('should fail gracefully when comparing non-existent baseline', () => {
      const baselinePath = join(testDir, 'non-existent-baseline.json');
      expect(existsSync(baselinePath)).toBe(false);
    });

    it('should detect breaking changes in baseline comparison', () => {
      // Simulate baseline comparison result
      const diff = {
        severity: 'breaking',
        toolsAdded: 0,
        toolsRemoved: 2,
        toolsModified: 1,
        behaviorChanges: [],
      };

      const hasBreaking = diff.severity === 'breaking';
      expect(hasBreaking).toBe(true);
    });

    it('should detect warning-level changes', () => {
      const diff = {
        severity: 'warning',
        toolsAdded: 1,
        toolsRemoved: 0,
        toolsModified: 0,
        behaviorChanges: [],
      };

      const hasWarning = diff.severity === 'warning';
      expect(hasWarning).toBe(true);
    });
  });

  describe('baseline format', () => {
    it('should create canonical baseline format', () => {
      const baseline = {
        version: '1.0.0',
        metadata: {
          mode: 'check',
          generatedAt: new Date().toISOString(),
          cliVersion: '1.0.0',
          serverCommand: 'npx test-server',
          durationMs: 1000,
          personas: [],
          model: 'none',
        },
        server: {
          name: 'test-server',
          version: '1.0.0',
          protocolVersion: '2024-11-05',
          capabilities: ['tools'],
        },
        capabilities: {
          tools: [
            {
              name: 'test_tool',
              description: 'A test tool',
              inputSchema: { type: 'object' },
              schemaHash: 'hash123',
            },
          ],
        },
        interviews: [],
        toolProfiles: [
          {
            name: 'test_tool',
            description: 'A test tool',
            schemaHash: 'hash123',
            assertions: [],
            securityNotes: [],
            limitations: [],
            behavioralNotes: [],
          },
        ],
        assertions: [],
        summary: 'Test baseline',
        hash: 'hash123',
      };

      // Verify format
      expect(baseline.version).toBe('1.0.0');
      expect(baseline.metadata.mode).toBe('check');
      expect(baseline.capabilities.tools).toHaveLength(1);
      expect(baseline.toolProfiles).toHaveLength(1);
    });
  });

  describe('interview progress tracking', () => {
    it('should track progress phases correctly', () => {
      const phases: string[] = [];

      const progressCallback = (progress: {
        phase: 'starting' | 'interviewing' | 'synthesizing' | 'complete';
        currentTool?: string;
        toolsCompleted: number;
        totalTools: number;
        questionsAsked: number;
      }) => {
        phases.push(progress.phase);
      };

      // Simulate progress updates
      progressCallback({ phase: 'starting', toolsCompleted: 0, totalTools: 3, questionsAsked: 0 });
      progressCallback({
        phase: 'interviewing',
        currentTool: 'tool1',
        toolsCompleted: 0,
        totalTools: 3,
        questionsAsked: 1,
      });
      progressCallback({
        phase: 'interviewing',
        currentTool: 'tool2',
        toolsCompleted: 1,
        totalTools: 3,
        questionsAsked: 3,
      });
      progressCallback({
        phase: 'synthesizing',
        toolsCompleted: 3,
        totalTools: 3,
        questionsAsked: 9,
      });
      progressCallback({ phase: 'complete', toolsCompleted: 3, totalTools: 3, questionsAsked: 9 });

      expect(phases).toEqual([
        'starting',
        'interviewing',
        'interviewing',
        'synthesizing',
        'complete',
      ]);
    });

    it('should track questions asked per tool', () => {
      let totalQuestions = 0;

      const progressCallback = (progress: { questionsAsked: number }) => {
        totalQuestions = progress.questionsAsked;
      };

      // Simulate asking questions
      progressCallback({ questionsAsked: 1 });
      progressCallback({ questionsAsked: 2 });
      progressCallback({ questionsAsked: 3 });
      progressCallback({ questionsAsked: 4 });
      progressCallback({ questionsAsked: 5 });

      expect(totalQuestions).toBe(5);
    });

    it('should track persona progress', () => {
      const progress = {
        phase: 'interviewing' as const,
        currentPersona: 'technical_writer',
        personasCompleted: 0,
        totalPersonas: 2,
        toolsCompleted: 2,
        totalTools: 5,
        questionsAsked: 6,
      };

      const totalToolCalls = progress.totalPersonas * progress.totalTools;
      const completedToolCalls =
        progress.personasCompleted * progress.totalTools + progress.toolsCompleted;

      expect(totalToolCalls).toBe(10);
      expect(completedToolCalls).toBe(2);
    });
  });

  describe('CLI option parsing', () => {
    it('should parse timeout option correctly', () => {
      const optionValue = '90000';
      const timeout = parseInt(optionValue, 10);

      expect(timeout).toBe(90000);
    });

    it('should parse max-questions option correctly', () => {
      const optionValue = '5';
      const maxQuestions = parseInt(optionValue, 10);

      expect(maxQuestions).toBe(5);
    });

    it('should use default values when options not provided', () => {
      const defaultTimeout = 60000;
      const defaultMaxQuestions = 3;

      const options = {
        timeout: undefined,
        maxQuestions: undefined,
      };

      const timeout = options.timeout ? parseInt(options.timeout, 10) : defaultTimeout;
      const maxQuestions = options.maxQuestions
        ? parseInt(options.maxQuestions, 10)
        : defaultMaxQuestions;

      expect(timeout).toBe(60000);
      expect(maxQuestions).toBe(3);
    });
  });

  describe('error handling', () => {
    it('should handle LLM client initialization failure', () => {
      // Simulate what happens when LLM client creation fails
      const createLLMClient = () => {
        throw new Error('Invalid API key');
      };

      expect(() => createLLMClient()).toThrow('Invalid API key');
    });

    it('should handle missing API key environment variable', () => {
      const config = {
        llm: {
          provider: 'openai',
          apiKey: undefined,
          apiKeyEnvVar: 'OPENAI_API_KEY',
        },
      };

      // Check if API key is available
      const apiKey = config.llm.apiKey || process.env[config.llm.apiKeyEnvVar];
      const hasKey = Boolean(apiKey);

      // In test environment, this would typically be false
      expect(typeof hasKey).toBe('boolean');
    });

    it('should handle MCP server connection failure', async () => {
      const mockClient = {
        connect: vi.fn().mockRejectedValue(new Error('Connection refused')),
        disconnect: vi.fn().mockResolvedValue(undefined),
      };

      await expect(mockClient.connect('npx', ['server'])).rejects.toThrow('Connection refused');
    });

    it('should handle server with no tools', () => {
      const discovery = {
        serverInfo: { name: 'empty-server', version: '1.0.0' },
        tools: [],
        prompts: [],
        capabilities: {},
      };

      const hasTools = discovery.tools.length > 0;
      expect(hasTools).toBe(false);
    });
  });

  describe('verbose output mode', () => {
    it('should output detailed progress in verbose mode', () => {
      const verbose = true;
      const progress = {
        phase: 'interviewing' as const,
        currentTool: 'read_file',
        toolsCompleted: 2,
        totalTools: 5,
      };

      if (verbose) {
        const message = `Interviewing tool: ${progress.currentTool} (${progress.toolsCompleted + 1}/${progress.totalTools})`;
        consoleOutput.push(message);
      }

      expect(consoleOutput).toContain('Interviewing tool: read_file (3/5)');
    });

    it('should output simple progress in non-verbose mode', () => {
      const verbose = false;
      const progress = {
        totalTools: 5,
        totalPersonas: 2,
        personasCompleted: 1,
        toolsCompleted: 3,
        questionsAsked: 12,
      };

      if (!verbose) {
        const totalToolCalls = progress.totalTools * progress.totalPersonas;
        const completedCalls =
          progress.personasCompleted * progress.totalTools + progress.toolsCompleted;
        const message = `\rInterviewing: ${completedCalls}/${totalToolCalls} tools, ${progress.questionsAsked} questions asked`;
        stdoutOutput.push(message);
      }

      expect(stdoutOutput.some((o) => o.includes('8/10 tools'))).toBe(true);
      expect(stdoutOutput.some((o) => o.includes('12 questions asked'))).toBe(true);
    });
  });

  describe('fail-on-drift flag', () => {
    it('should exit with error on breaking changes when flag is set', () => {
      const failOnDrift = true;
      const diff = { severity: 'breaking' };

      const shouldExit = failOnDrift && diff.severity === 'breaking';
      expect(shouldExit).toBe(true);
    });

    it('should exit with error on warnings when flag is set', () => {
      const failOnDrift = true;
      const diff = { severity: 'warning' };

      const shouldExit = failOnDrift && diff.severity === 'warning';
      expect(shouldExit).toBe(true);
    });

    it('should not exit on info-level changes', () => {
      const failOnDrift = true;
      const diff = { severity: 'info' };

      const shouldExit =
        failOnDrift && (diff.severity === 'breaking' || diff.severity === 'warning');
      expect(shouldExit).toBe(false);
    });

    it('should not exit on changes when flag is not set', () => {
      const failOnDrift = false;
      const diff = { severity: 'breaking' };

      const shouldExit = failOnDrift && diff.severity === 'breaking';
      expect(shouldExit).toBe(false);
    });
  });

  describe('output directory handling', () => {
    it('should use current directory when output not specified', () => {
      const options = { output: undefined };
      const configOutput = undefined;

      const outputDir = options.output ?? configOutput ?? '.';
      expect(outputDir).toBe('.');
    });

    it('should use CLI option over config setting', () => {
      const options = { output: '/custom/path' };
      const configOutput = '/config/path';

      const outputDir = options.output ?? configOutput ?? '.';
      expect(outputDir).toBe('/custom/path');
    });

    it('should create nested output directories', () => {
      const nestedDir = join(testDir, 'deeply', 'nested', 'output');
      mkdirSync(nestedDir, { recursive: true });

      expect(existsSync(nestedDir)).toBe(true);
    });
  });

  describe('model override', () => {
    it('should use CLI model option over config', () => {
      const cliModel = 'gpt-4-turbo';
      const configModel = 'gpt-4o';

      const model = cliModel ?? configModel;
      expect(model).toBe('gpt-4-turbo');
    });

    it('should fall back to config model when CLI option not provided', () => {
      const cliModel = undefined;
      const configModel = 'gpt-4o';

      const model = cliModel ?? configModel;
      expect(model).toBe('gpt-4o');
    });
  });

  describe('debug mode', () => {
    it('should pass debug flag to MCP client', () => {
      const options = { debug: true };

      // In real code: new MCPClient({ timeout, debug: options.debug })
      const clientConfig = { timeout: 60000, debug: options.debug };

      expect(clientConfig.debug).toBe(true);
    });
  });
});

describe('interview command integration scenarios', () => {
  let testDir: string;
  let originalCwd: string;

  beforeEach(() => {
    configureLogger({ level: 'silent' });
    testDir = join(tmpdir(), `bellwether-cli-interview-integration-${Date.now()}`);
    mkdirSync(testDir, { recursive: true });
    originalCwd = process.cwd();
    process.chdir(testDir);
  });

  afterEach(() => {
    process.chdir(originalCwd);
    resetLogger();
    vi.restoreAllMocks();
    try {
      rmSync(testDir, { recursive: true, force: true });
    } catch {
      // Ignore cleanup errors
    }
  });

  it('should handle full interview workflow simulation', () => {
    // Simulate a complete interview workflow
    const workflow = {
      connected: false,
      discovered: false,
      interviewed: false,
      documented: false,
    };

    // 1. Connect to server
    workflow.connected = true;

    // 2. Discover capabilities
    const discovery = {
      serverInfo: { name: 'test-server', version: '1.0.0' },
      tools: [
        { name: 'read_file', description: 'Read file contents' },
        { name: 'write_file', description: 'Write file contents' },
      ],
      prompts: [],
      capabilities: { tools: {} },
    };
    workflow.discovered = true;

    // 3. Interview tools
    const toolProfiles = discovery.tools.map((tool) => ({
      name: tool.name,
      description: tool.description,
      interactions: [],
      behavioralNotes: ['Works as expected'],
      limitations: [],
      securityNotes: [],
    }));
    workflow.interviewed = true;

    // 4. Generate documentation
    const agentsMdPath = join(testDir, 'AGENTS.md');
    writeFileSync(agentsMdPath, '# Test Server\n\n## Tools\n\n### read_file\n');
    workflow.documented = existsSync(agentsMdPath);

    expect(workflow.connected).toBe(true);
    expect(workflow.discovered).toBe(true);
    expect(workflow.interviewed).toBe(true);
    expect(workflow.documented).toBe(true);
    expect(toolProfiles).toHaveLength(2);
  });

  it('should handle interview with baseline creation', () => {
    // Create interview result
    const result = {
      discovery: {
        serverInfo: { name: 'test', version: '1.0.0' },
        tools: [{ name: 'tool1' }],
      },
      toolProfiles: [{ name: 'tool1', behavioralNotes: ['Note 1'] }],
      metadata: { durationMs: 5000, toolCallCount: 10, errorCount: 1 },
    };

    // Save baseline
    const baselinePath = join(testDir, 'baseline.json');
    const baseline = {
      version: '1.0.0',
      metadata: {
        mode: 'check',
        generatedAt: new Date().toISOString(),
        cliVersion: '1.0.0',
        serverCommand: 'npx test-server',
        durationMs: 1,
        personas: [],
        model: 'none',
      },
      server: {
        name: 'test',
        version: '1.0.0',
        protocolVersion: '2024-11-05',
        capabilities: ['tools'],
      },
      capabilities: {
        tools: result.discovery.tools.map((t) => ({
          name: t.name,
          description: 'Test tool',
          inputSchema: { type: 'object', properties: {} },
          schemaHash: 'abc123',
        })),
      },
      interviews: [],
      toolProfiles: [],
      assertions: [],
      summary: 'Test baseline',
      hash: 'abc123',
    };
    writeFileSync(baselinePath, JSON.stringify(baseline, null, 2));

    expect(existsSync(baselinePath)).toBe(true);
    const loaded = JSON.parse(readFileSync(baselinePath, 'utf-8'));
    expect(loaded.version).toBe('1.0.0');
    expect(loaded.capabilities.tools[0].name).toBe('tool1');
  });

  it('should handle interview with baseline comparison', () => {
    // Create previous baseline
    const previousBaseline = {
      version: '1.0.0',
      metadata: {
        mode: 'check',
        generatedAt: '2024-01-01T00:00:00Z',
        cliVersion: '1.0.0',
        serverCommand: 'npx test-server',
        durationMs: 1,
        personas: [],
        model: 'none',
      },
      server: {
        name: 'test',
        version: '1.0.0',
        protocolVersion: '2024-11-05',
        capabilities: ['tools'],
      },
      capabilities: {
        tools: [
          { name: 'tool1', description: 'Tool 1', inputSchema: {}, schemaHash: 'old-hash' },
          { name: 'tool2', description: 'Tool 2', inputSchema: {}, schemaHash: 'removed' },
        ],
      },
      interviews: [],
      toolProfiles: [],
      assertions: [],
      summary: 'Previous baseline',
      hash: 'prev-hash',
    };
    const baselinePath = join(testDir, 'previous-baseline.json');
    writeFileSync(baselinePath, JSON.stringify(previousBaseline));

    // Create current baseline (from interview)
    const currentBaseline = {
      version: '1.0.0',
      metadata: {
        mode: 'check',
        generatedAt: new Date().toISOString(),
        cliVersion: '1.0.0',
        serverCommand: 'npx test-server',
        durationMs: 1,
        personas: [],
        model: 'none',
      },
      server: {
        name: 'test',
        version: '1.0.0',
        protocolVersion: '2024-11-05',
        capabilities: ['tools'],
      },
      capabilities: {
        tools: [
          { name: 'tool1', description: 'Tool 1', inputSchema: {}, schemaHash: 'new-hash' },
          { name: 'tool3', description: 'Tool 3', inputSchema: {}, schemaHash: 'added' },
        ],
      },
      interviews: [],
      toolProfiles: [],
      assertions: [],
      summary: 'Current baseline',
      hash: 'current-hash',
    };

    // Compare baselines
    const previous = new Set(previousBaseline.capabilities.tools.map((t) => t.name));
    const current = new Set(currentBaseline.capabilities.tools.map((t) => t.name));

    const added = [...current].filter((t) => !previous.has(t));
    const removed = [...previous].filter((t) => !current.has(t));
    const modified = [...current].filter((t) => {
      if (!previous.has(t)) return false;
      const prevTool = previousBaseline.capabilities.tools.find((p) => p.name === t);
      const currTool = currentBaseline.capabilities.tools.find((c) => c.name === t);
      return prevTool?.schemaHash !== currTool?.schemaHash;
    });

    expect(added).toEqual(['tool3']);
    expect(removed).toEqual(['tool2']);
    expect(modified).toEqual(['tool1']);
  });
});

describe('interview command presets', () => {
  describe('preset configurations', () => {
    const PRESETS = {
      docs: {
        personas: ['technical_writer'],
        maxQuestions: 3,
        description: 'Documentation-focused: Technical Writer persona, 3 questions/tool',
      },
      security: {
        personas: ['technical_writer', 'security_tester'],
        maxQuestions: 3,
        description: 'Security audit: Technical + Security personas, 3 questions/tool',
      },
      thorough: {
        personas: ['technical_writer', 'security_tester', 'qa_engineer', 'novice_user'],
        maxQuestions: 5,
        description: 'Comprehensive: All 4 personas, 5 questions/tool',
      },
      ci: {
        personas: ['technical_writer'],
        maxQuestions: 1,
        description: 'CI/CD optimized: Technical Writer only, 1 question/tool (fastest)',
      },
    };

    it('should have docs preset with technical writer and 3 questions', () => {
      const preset = PRESETS['docs'];
      expect(preset.personas).toContain('technical_writer');
      expect(preset.personas).toHaveLength(1);
      expect(preset.maxQuestions).toBe(3);
    });

    it('should have security preset with two personas', () => {
      const preset = PRESETS['security'];
      expect(preset.personas).toContain('technical_writer');
      expect(preset.personas).toContain('security_tester');
      expect(preset.personas).toHaveLength(2);
      expect(preset.maxQuestions).toBe(3);
    });

    it('should have thorough preset with all personas and 5 questions', () => {
      const preset = PRESETS['thorough'];
      expect(preset.personas).toHaveLength(4);
      expect(preset.maxQuestions).toBe(5);
    });

    it('should have ci preset optimized for speed', () => {
      const preset = PRESETS['ci'];
      expect(preset.personas).toHaveLength(1);
      expect(preset.maxQuestions).toBe(1);
    });

    it('should validate preset names', () => {
      const validPresets = ['docs', 'security', 'thorough', 'ci'];
      const invalidPreset = 'invalid-preset';

      expect(validPresets.includes('docs')).toBe(true);
      expect(validPresets.includes(invalidPreset)).toBe(false);
    });
  });

  describe('preset override behavior', () => {
    it('should override manual persona selection when preset is specified', () => {
      const options = {
        preset: 'security',
        personas: 'novice', // This should be ignored
      };

      // Preset takes precedence
      const presetPersonas = ['technical_writer', 'security_tester'];
      const finalPersonas = options.preset ? presetPersonas : options.personas?.split(',');

      expect(finalPersonas).toEqual(['technical_writer', 'security_tester']);
    });

    it('should override quick mode when preset is specified', () => {
      const options = {
        preset: 'thorough',
        quick: true, // This should be ignored
      };

      const presetMaxQuestions = 5;
      const quickModeQuestions = 1;
      const defaultQuestions = 3;

      const finalQuestions = options.preset
        ? presetMaxQuestions
        : options.quick
          ? quickModeQuestions
          : defaultQuestions;

      expect(finalQuestions).toBe(5);
    });

    it('should use manual settings when no preset is specified', () => {
      const options = {
        personas: 'qa,novice',
        maxQuestions: 4,
      };

      const finalPersonas = options.personas.split(',');
      const finalQuestions = options.maxQuestions;

      expect(finalPersonas).toEqual(['qa', 'novice']);
      expect(finalQuestions).toBe(4);
    });
  });
});
