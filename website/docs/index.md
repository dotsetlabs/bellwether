---
slug: /
title: Introduction
sidebar_position: 1
---

# Bellwether

**Automated behavioral documentation for MCP servers through LLM-guided testing.**

Bellwether is a CLI tool that generates comprehensive behavioral documentation for [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) servers. Instead of relying on manually written docs, Bellwether **interviews** your MCP server by:

1. **Discovering** available tools, prompts, and resources
2. **Generating** realistic test scenarios using an LLM
3. **Executing** tests and analyzing actual responses
4. **Synthesizing** findings into actionable documentation

## Why Bellwether?

| Problem | Solution |
|:--------|:---------|
| Documentation says one thing, but what does the server actually do? | **Trust but verify** - Interview the server to document real behavior |
| Breaking changes slip into production unnoticed | **Drift detection** - Catch behavioral changes before they hit production |
| Security vulnerabilities are hard to discover manually | **Security insights** - Persona-based adversarial testing |
| Manual testing is slow and expensive | **CI/CD integration** - Automated regression testing for MCP servers |

## Key Features

- **AGENTS.md Generation** - Human-readable behavioral documentation generated automatically from actual server responses
- **Drift Detection** - Compare baselines to detect behavioral changes between versions with semantic diff analysis
- **Multi-Persona Testing** - Security tester, QA engineer, technical writer, and novice user personas for comprehensive coverage
- **Cloud Sync** - Optional cloud storage for baseline history and verification badges
- **Multiple Output Formats** - Markdown, JSON, JUnit XML, and SARIF for GitHub Code Scanning

## How It Works

```
   MCP Server           Bellwether                    Output
       |                   |                          |
       |  tools/list       |                          |
       |<------------------|                          |
       |                   |                          |
       |   tools/call      |   LLM generates          |
       |<------------------|   test scenarios         |
       |                   |                          |
       |   responses       |                          |
       |------------------>|   Analyze behavior       |
       |                   |                          |
       |                   |----------------------->  AGENTS.md
       |                   |                          baseline.json
```

## Output Example

Bellwether generates `AGENTS.md` files documenting observed server behavior:

```markdown
# @modelcontextprotocol/server-filesystem

> Generated by Bellwether on 2026-01-12

## Overview

A file management server providing tools for reading, writing, and searching files.

## Tools

### read_file

Read contents of a file from the specified path.

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| path | string | yes | Path to the file to read |

**Observed Behavior:**
- Returns file contents as UTF-8 text
- Binary files are returned as base64-encoded content
- Maximum file size: 10MB

**Limitations:**
- Cannot read files outside configured root directory

**Security Considerations:**
- Path traversal attempts (../) are normalized within root
```

## Cost Efficiency

Bellwether uses LLMs for intelligent testing. Typical costs per interview (10 tools, 3 questions each):

| Model | Cost | Quality |
|:------|:-----|:--------|
| `gpt-4o-mini` | ~$0.02 | Good (recommended for CI) |
| `claude-3-5-haiku` | ~$0.03 | Good |
| `gpt-4o` | ~$0.13 | Best |
| `claude-sonnet` | ~$0.13 | Best |
| Ollama (local) | Free | Variable |

Use `--quick` flag in CI for fastest, cheapest runs (~$0.01).

## Quick Example

```bash
# Install
npm install -g @dotsetlabs/bellwether

# Set your API key
export OPENAI_API_KEY=sk-xxx

# Interview an MCP server
bellwether interview npx @modelcontextprotocol/server-filesystem /tmp

# Output: AGENTS.md with behavioral documentation
```

## Next Steps

- [Installation](/installation) - Install Bellwether and configure your LLM provider
- [Quick Start](/quickstart) - Run your first interview in 5 minutes
- [CLI Reference](/cli/interview) - Full command documentation
- [CI/CD Integration](/guides/ci-cd) - Automate behavioral testing in your pipeline
